{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80b1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential, clone_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D,Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b347ed5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/taesan/Udemy/reinforcement'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c0b0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " permute (Permute)           (None, 200, 200, 4)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 49, 49, 32)        8224      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 49, 49, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 23, 23, 64)        32832     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 23, 23, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 64)        65600     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 20, 20, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               13107712  \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13216420 (50.42 MB)\n",
      "Trainable params: 13216420 (50.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taesan/anaconda3/envs/tf/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:168: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/taesan/anaconda3/envs/tf/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/taesan/anaconda3/envs/tf/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: uint8\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"snake:snake-v0\",render_mode=\"human\")\n",
    "env.reset()\n",
    "\n",
    "num_observations = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "IMG_SHAPE = (200,200)\n",
    "WINDOW_LENGTH = 4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = Sequential(\n",
    "    \n",
    "    [Permute( (2,3,1), input_shape=(WINDOW_LENGTH,IMG_SHAPE[0],IMG_SHAPE[1])),\n",
    "    Convolution2D(32, (8,8), strides= (4,4),kernel_initializer=\"he_normal\"),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Convolution2D(64, (4,4), strides= (2,2),kernel_initializer=\"he_normal\"),\n",
    "    Activation('relu'),\n",
    "     \n",
    "    Convolution2D(64, (4,4), strides= (1,1),kernel_initializer=\"he_normal\"),\n",
    "    Activation('relu'),\n",
    "        \n",
    "    Flatten(),\n",
    "    Dense(512),\n",
    "     Activation('relu'),\n",
    "     \n",
    "     Dense(num_actions),\n",
    "    Activation('linear')\n",
    "    ]\n",
    "    \n",
    ")\n",
    "print(model.summary())\n",
    "target_model = clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86964bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "#declare hyperparameters\n",
    "EPISODES = 1000 \n",
    "LEARNING_RATE = 0.001 #LEARNING RATE FOR MODEL\n",
    "GAMMA = 0.95 #DISCOUNT RATE\n",
    "\n",
    "epsilon = 1.0 #greedy-epsilon\n",
    "EPSILON_REDUCE = 0.995\n",
    "\n",
    "replay_buffer = deque(maxlen=50000)\n",
    "image_buffer= deque(maxlen=WINDOW_LENGTH)\n",
    "update_target_model = 10\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=Adam(learning_rate=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ab3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process observation\n",
    "def process_observation(observation):\n",
    "    img = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "def process_reward(reward):\n",
    "    return np.clip(reward, -1.0,1.0)\n",
    "\n",
    "#action selection\n",
    "def epsilon_greedy_action_selection(model, epsilon, observation):\n",
    "    observation = observation.reshape(1,WINDOW_LENGTH,IMG_SHAPE[0],IMG_SHAPE[1])\n",
    "    #Exploitation\n",
    "    if np.random.random() > epsilon:\n",
    "        prediction = model.predict((observation), verbose=0)\n",
    "        action = np.argmax(prediction)\n",
    "        \n",
    "    #Exploration\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "    return action\n",
    "    \n",
    "# reduce epsilon\n",
    "def reduce_epsilon(epsilon,epoch):\n",
    "    return min_epsilon + (max_epsilon-min_epsilon)*np.exp(-decay_rate * epoch)\n",
    "\n",
    "def update_model_handler(epoch,update_target_model, model, target_model):\n",
    "    if epoch > 0 and epoch % update_target_model == 0:\n",
    "        target_model.set_weights(model.get_weights())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d788bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay(replay_buffer,batch_size, model, target_model):\n",
    "    if len(replay_buffer)< batch_size:\n",
    "        return\n",
    "    \n",
    "    samples = random.sample(replay_buffer, batch_size)\n",
    "    \n",
    "    target_batch=[]\n",
    "    \n",
    "    zipped_samples = list(zip(*samples))\n",
    "    states, actions ,rewards, new_states, dones, truncated = zipped_samples\n",
    "    targets = target_model.predict(np.array(states),verbose=False)\n",
    "    \n",
    "    q_values = model.predict( np.array(new_states),verbose=False)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        q_value = max(q_values[i])\n",
    "    \n",
    "        target = targets[i].copy()\n",
    "        if dones[i] or truncated[i]:\n",
    "            target[actions[i]] = rewards[i]\n",
    "        else:\n",
    "            target[actions[i]] =rewards[i]+q_value * GAMMA\n",
    "        target_batch.append(target)\n",
    "    \n",
    "    model.fit(np.array(states),np.array(target_batch),verbose=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taesan/anaconda3/envs/tf/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:232: UserWarning: \u001b[33mWARN: Expects `truncated` signal to be a boolean, actual type: <class 'int'>\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/taesan/anaconda3/envs/tf/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float64, actual type: uint8\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 , Best so far: 0\n",
      "Episode 25 , Best so far: 0\n",
      "Episode 50 , Best so far: 0\n",
      "Episode 75 , Best so far: 0\n"
     ]
    }
   ],
   "source": [
    "best_so_far = 0\n",
    "observation, _ = env.reset()\n",
    "preprocessed_obs = process_observation(observation)\n",
    "for i in range(WINDOW_LENGTH):\n",
    "    image_buffer.append(preprocessed_obs)\n",
    "  \n",
    "image_buffer_numpy = np.stack((image_buffer[0],image_buffer[1],image_buffer[2],image_buffer[3]),axis=0)\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    observation, _ = env.reset()\n",
    "    preprocessed_obs = process_observation(observation)\n",
    "    done = False\n",
    "    truncated = False\n",
    "    \n",
    "    points = 0\n",
    "    \n",
    "    while not (done or truncated):\n",
    "        action = epsilon_greedy_action_selection(model,epsilon,image_buffer_numpy)\n",
    "    \n",
    "        next_observation, reward, done, truncated, info = env.step(action)\n",
    "        procssed_next_observation = process_observation(next_observation)\n",
    "        \n",
    "        preprocessed_obs = process_observation(observation)\n",
    "        preprocessed_reward = process_reward(reward)\n",
    "        \n",
    "        image_buffer.append(preprocessed_obs)\n",
    "        image_buffer_numpy = np.stack((image_buffer[0],image_buffer[1],image_buffer[2],image_buffer[3]),axis=0)\n",
    "        next_observation_numpy = np.stack((image_buffer[1],image_buffer[2],image_buffer[3],preprocessed_obs),axis=0)\n",
    "\n",
    "        replay_buffer.append((image_buffer_numpy, action, reward, next_observation_numpy,done,truncated))\n",
    "        \n",
    "        \n",
    "        observation = next_observation\n",
    "        points += reward\n",
    "        \n",
    "        replay(replay_buffer,32, model, target_model)\n",
    "        \n",
    "    epsilon *= EPSILON_REDUCE\n",
    "    \n",
    "    update_model_handler(episode, update_target_model, model,target_model)\n",
    "    \n",
    "    if points > best_so_far:\n",
    "        best_so_far= points\n",
    "    if episode %25 == 0:\n",
    "        print(\"Episode {0:} , Best so far: {1:}\".format(episode,best_so_far))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env =gym.make(\"snake:snake-v0\",render_mode=\"human\")\n",
    "state, _ = test_env.reset()\n",
    "preprocessed_obs = process_observation(observation)\n",
    "for i in range(WINDOW_LENGTH):\n",
    "    image_buffer.append(preprocessed_obs)\n",
    "  \n",
    "image_buffer_numpy = np.stack((image_buffer[0],image_buffer[1],image_buffer[2],image_buffer[3]),axis=0).reshape(1,WINDOW_LENGTH,IMG_SHAPE[0],IMG_SHAPE[1])\n",
    "\n",
    "point = 0\n",
    "done = False\n",
    "truncated = False\n",
    "for steps in range(300):\n",
    "    action = np.argmax(model.predict(image_buffer_numpy))\n",
    "    \n",
    "    state, reward, done, truncated , info = test_env.step(action)\n",
    "    image_buffer.append(preprocessed_obs)\n",
    "    image_buffer_numpy = np.stack((image_buffer[0],image_buffer[1],image_buffer[2],image_buffer[3]),axis=0).reshape(1,WINDOW_LENGTH,IMG_SHAPE[0],IMG_SHAPE[1])\n",
    "    \n",
    "    point+= reward\n",
    "    if done or truncated: \n",
    "        print(\"done\")\n",
    "        break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
